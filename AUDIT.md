# 滑块轨迹生成项目审核与优化建议

## 一、与三个目标的对应情况

### 1. 生成可靠、不易被识别的轨迹

**现状：**
- 使用 Conditional WGAN-GP，判别器能学到真实轨迹的分布，有利于“像人”。
- 生成器有 LSTM + 逐步噪声（step_noise），利于局部随机性，避免过于平滑。
- 训练中有几何约束（终点对齐、Y 回零）、平滑（jerk、加速度）、回撤、分散度、终点减速、抖动等辅助损失，轨迹在物理上合理。

**可优化点：**
- 判别器只见过 `dataset/train` 的分布；若采集环境单一（例如只有鼠标），生成轨迹可能只在“鼠标风格”上过关，建议采集时包含多种设备/速度。
- 推理时的 `_estimate_duration_ms` 为启发式公式，若与真实人工总时长分布差异大，可能被“总时长异常”检测到。可考虑：用人工数据拟合一条 duration ~ distance 的曲线，或增加“目标时长”条件（需改模型与数据格式）。

---

### 2. 轨迹生成的通用性（任意起点与终点）

**现状：**
- 条件只有**目标距离**一个标量：`cond = target_distance / D_MAX`，且 `D_MAX = 400`。
- 训练/推理都假设起点为 (0,0)，终点为 (target_distance, ~0)，即**水平滑块**；没有显式的 2D 起点/终点，通用性体现在“任意目标距离”上。
- 预处理中 condition 来自轨迹实际位移 `(x[-1]-x[0])/D_MAX`，与目标距离一致，设计合理。
- 推理时对 `target_distance` 做 `clip(0, D_MAX)`，即 **>400px 被压成 1.0**；训练数据里目标距离多在约 120–270px（cond ≈ 0.3–0.67），**过小（如 50px）或过大（如 400px+）的泛化未在数据上充分覆盖**。

**建议：**
- **数据覆盖：** 尽量保证训练集中目标距离在 50–400px 都有足够样本，尤其 50–100px 与 350–400px，避免两端外推。
- **超 400px：** 若业务需要 400px 以上，可选：(1) 提高 `D_MAX`（如 500）并补充大距离样本；或 (2) 保持 400，在文档中说明超出部分用 clip 的精度损失。
- **真正的 2D 起点/终点：** 若将来要做“任意 (x0,y0)→(x1,y1)”，需要把条件改为 (dx_total, dy_total) 或 (x0,y0,x1,y1)，并相应改预处理与推理；当前架构是“任意水平距离”的通用性。

---

### 3. 通过通用滑块人工行为校验（核心观察指标）

**现状：**
- `main.py` 里已有速度、加速度、抖动、平均速度-路径长等**可视化对比**，但没有：
  - 单条轨迹的**指标数值**汇总接口；
  - 基于人工数据统计的**通过/不通过**判定；
  - 训练或推理流程中的**自动校验**。

**已做优化：**
- 新增 **`validate.py`**：
  - `compute_trajectory_metrics(points)`：输出总时长、总位移、平均/最大速度、速度标准差、加速度均值/标准差/最大值、抖动均值、Y 范围、最大回撤等；
  - `build_human_stats(trajectories)`：从多个人工轨迹算各指标百分位（如 5%–95%）；
  - `check_trajectory_pass(points, human_stats)`：判断轨迹是否落在人工范围内（可放宽 tolerance）；
  - 支持从 `dataset/train` 建 `human_stats.json`，并对 `model.json` 做示例校验。
- 运行 `uv run python validate.py` 可生成 `dataset/compare/human_stats.json` 并在有模型轨迹时做一次校验。

**建议用法：**
- 训练或上线前：对一批生成轨迹跑 `check_trajectory_pass`，不通过的可丢弃或重生成。
- 将 `human_stats.json` 纳入版本/复现，校验阈值可随人工数据更新而更新。

---

## 二、其他值得优化的点

### 1. 训练与推理的 checkpoint 路径

- **问题：** 训练保存的是 `wgan_v2_final.pt` 与 `wgan_v2_epoch*.pt`，而 `inference.py`、`main.py`、`export_onnx.py`、README 默认使用 `checkpoints/wgan.pt`。
- **已做：** 训练结束除保存 `wgan_v2_final.pt` 外，**同时复制为 `wgan.pt`**，保证不改推理代码即可用默认路径。

### 2. 训练日志

- **问题：** 辅助损失分量（geom、smooth、dd、stop、jitter）未打印，调参不便。
- **已做：** 每 500 epoch 打印一次上述 aux 分量。

### 3. 验证集与早停

- **现状：** 仅用 `dataset/train`，无验证集与早停。
- **建议：** 使用 `dataset/test` 做验证：每 N 个 epoch 在验证集上算 D/G 损失或生成几条轨迹做 `validate.check_trajectory_pass`，若连续若干轮变差则早停，避免过拟合。

### 4. 推理时终点与总时长

- **终点：** 已通过“按比例缩放到 target_distance”和可选的 `force_monotone_x` 保证 X 终点；Y 保持模型输出，一般接近 0。
- **总时长：** 目前用 `_estimate_duration_ms(target_distance)` 的启发式；若风控对“总时长分布”敏感，建议用人工数据拟合并替换该函数，或改为“按人工分布采样总时长再插值”。

### 5. 数据与预处理

- **重采样：** 等时间间隔重采样到 128 步，把速度信息编码进 dx/dy，设计合理。
- **condition 一致性：** 训练用轨迹实际位移做 cond，与推理时用页面 `target_distance` 做 cond 一致（推理时即目标距离），无需改。
- **D_MAX/NORM_SCALE：** 与 `export_onnx.py`、`example/onnx_runtime_demo.py` 一致即可；若改预处理常量，需同步改推理与 ONNX 示例。

### 6. 判别器与生成器平衡

- **现状：** D 每步更新，G 每 `d_steps` 步更新，且对 G 做了梯度裁剪，有利于稳定。
- 若发现 D 损失很快趋近 0 或 G 损失不降，可适当调 `d_steps` 或学习率。

---

## 三、小结

| 目标                     | 现状评价           | 已做/建议                                       |
|--------------------------|--------------------|-------------------------------------------------|
| 可靠、不易识别           | 架构与损失设计到位 | 丰富采集来源；可校准总时长分布                   |
| 任意起点终点（距离通用） | 任意水平距离       | 扩充 50–100、350–400px 数据；超 400px 需扩 D_MAX 或说明 |
| 通过人工行为校验         | 此前仅有可视化     | 新增 `validate.py`，指标 + 人工阈值 + 通过判定   |
| 工程一致性               | checkpoint 名不一  | 训练结束另存 `wgan.pt`；补充 aux 日志           |

按当前代码与本次改动，训练后可直接用 `checkpoints/wgan.pt` 做推理与对比；用 `validate.py` 建好 `human_stats.json` 后，即可对生成轨迹做可重复的“人工行为通过/不通过”校验。
